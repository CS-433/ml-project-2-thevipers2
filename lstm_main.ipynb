{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning - Project 2:\n",
    "# _Unsteady parametrized Stokes equations in a 2D arterial bifurcation with stenosis: design of a LSTM Autoencoder for data compression_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we continue our study by focusing on __Long Short-Term Memory Autoencoder__ , or LSTM AE,using the same dataset generated on the first jupyter notebook `main.ipynb`.\n",
    "Indeed, recurrent neural networks, such as LSTM, network are specifically designed to support sequences of input data. And since our simulations are time-dependent, it is interesting to use this specific model for our application."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abbreviations used:\n",
    "- $N_u$ = total number of spatial points per simulation\n",
    "- $N_t$ = total number of time steps per simulation\n",
    "- $N_s$ = total number of simulations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1. Data exploration](#data_exploration) \n",
    "- [Imports](#1imports)\n",
    "- [Pathways](#1pathways)\n",
    "- [Loading](#1load)\n",
    "- [Exploration](#1exploration)\n",
    "\n",
    "[2. Data preprocessing](#preprocessing)\n",
    "\n",
    "[3. Pickle](#pickle)\n",
    "\n",
    "[4. LSTM Autoencoder](#autoencoder)\n",
    "\n",
    "[5. Discussions and conclusion](#ccl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data exploration  <a name=\"data_exploration\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports  <a name=\"1imports\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from helpers import *\n",
    "from preprocessing import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "from LSTM import *\n",
    "from crossvalidation_lstm import *\n",
    "import _pickle as cPickle\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(1)\n",
    "seed = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have already saved the pickle files, you can already jump [here](#start_pickle)!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pathways <a name=\"1pathways\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = 'data/'\n",
    "DATA_Ux_PATH = DATA_PATH + 'u1_very_small.csv.bz2'\n",
    "DATA_Uy_PATH = DATA_PATH + 'u2_very_small.csv.bz2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading <a name=\"1load\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the data which consists of 2 matrices Ux, Uy denoting the x and y coordinates of the speed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading\n",
    "Ux_pd = pd.read_csv(DATA_Ux_PATH, header=None)\n",
    "Uy_pd = pd.read_csv(DATA_Uy_PATH, header=None)\n",
    "# Converting from dataframe to numpy\n",
    "Ux = Ux_pd.to_numpy()\n",
    "Uy = Uy_pd.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploration <a name=\"1exploration\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a closer look at our imported data sets. The columns represent the time steps and the rows represent a point of our blood vessel mesh and each 5509 row a new simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our input array Ux is of shape: (137725, 110)\n",
      "Our input array Uy is of shape: (137725, 110)\n",
      "Printing a row of Ux: \n",
      " [0.0694243  0.27537487 0.60389834 1.02538242 1.49979277 1.9813229\n",
      " 2.42318455 2.78232553 3.02371067 3.12378595 3.22605803 3.32166836\n",
      " 3.41249686 3.49946177 3.58301614 3.66339786 3.74073801 3.81511138\n",
      " 3.88656184 3.95511576 4.02078945 4.08359325 4.14353388 4.20061589\n",
      " 4.2548424  4.30621561 4.35473712 4.40040807 4.44322934 4.48320158\n",
      " 4.52032526 4.55460075 4.58602833 4.61460821 4.64034055 4.66322547\n",
      " 4.68326307 4.70045341 4.71479655 4.72629252 4.73494137 4.7407431\n",
      " 4.74369775 4.74423086 4.74375285 4.74246986 4.74042825 4.73764939\n",
      " 4.73414407 4.72991811 4.7249748  4.71931611 4.71294324 4.70585693\n",
      " 4.6980577  4.68954587 4.68032167 4.67038525 4.65973675 4.64837623\n",
      " 4.63630377 4.6235194  4.61002317 4.5958151  4.5808952  4.5652635\n",
      " 4.54892001 4.53186473 4.51409767 4.49561883 4.47642823 4.45652585\n",
      " 4.43591171 4.41458581 4.39254814 4.36979872 4.34633752 4.32216457\n",
      " 4.29727986 4.27168339 4.24537516 4.21835516 4.19062341 4.1621799\n",
      " 4.13302463 4.1031576  4.07257881 4.04128826 4.00928595 3.97657188\n",
      " 3.94314606 3.90900847 3.87415912 3.83859802 3.80232515 3.76534053\n",
      " 3.72764415 3.689236   3.6501161  3.61028444 3.56974102 3.52848584\n",
      " 3.4865189  3.4438402  3.40044974 3.35634752 3.31153355 3.26600781\n",
      " 3.21977031 3.17282106] \n",
      "\n",
      "Printing a row of Uy: \n",
      " [0.00067075 0.00314395 0.0081191  0.01585384 0.02617912 0.0385416\n",
      " 0.05208035 0.06573238 0.07835575 0.08885756 0.09779466 0.10544569\n",
      " 0.1120431  0.11779068 0.12286148 0.12739624 0.13150532 0.13527295\n",
      " 0.13876218 0.14201954 0.14507906 0.14796547 0.15069666 0.15328552\n",
      " 0.15574136 0.15807087 0.16027887 0.16236883 0.16434326 0.16620397\n",
      " 0.16795225 0.16958906 0.17111508 0.1725308  0.17383659 0.1750327\n",
      " 0.17611934 0.17709663 0.17796468 0.17872356 0.17937332 0.17991401\n",
      " 0.18034566 0.1806724  0.18091083 0.18107502 0.18117609 0.18122281\n",
      " 0.18122208 0.18117917 0.18109807 0.18098175 0.1808324  0.18065161\n",
      " 0.18044053 0.18020003 0.17993069 0.17963297 0.17930717 0.17895353\n",
      " 0.17857222 0.17816334 0.177727   0.17726324 0.17677213 0.17625368\n",
      " 0.17570793 0.17513488 0.17453457 0.17390698 0.17325214 0.17257004\n",
      " 0.17186069 0.17112409 0.17036024 0.16956915 0.16875082 0.16790524\n",
      " 0.16703242 0.16613236 0.16520505 0.16425051 0.16326872 0.16225969\n",
      " 0.16122342 0.1601599  0.15906915 0.15795116 0.15680592 0.15563344\n",
      " 0.15443372 0.15320676 0.15195256 0.15067112 0.14936244 0.14802651\n",
      " 0.14666335 0.14527294 0.14385529 0.14241041 0.14093828 0.1394389\n",
      " 0.13791229 0.13635844 0.13477734 0.13316901 0.13153343 0.12987061\n",
      " 0.12818056 0.12646326] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Our input array Ux is of shape:\",Ux.shape)\n",
    "print(\"Our input array Uy is of shape:\",Uy.shape)\n",
    "print(\"Printing a row of Ux:\", '\\n', Ux[10,:], '\\n')\n",
    "print(\"Printing a row of Uy:\", '\\n', Uy[10,:], '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the rest of the analysis, we need to figure out the number of simulation step. As we know that we previsouly generated 25 simulations on Matlab and all the new simulations are appended row-wise, we can deduce it with the following computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We ran  25 simulations with different parameters for each simulation (parameters of the stenosis and resistance of the blood flow in the bifurcations)\n",
      "1 simulation calculate the velocities of the blood flow at 5509 different positions and at 110 different times\n"
     ]
    }
   ],
   "source": [
    "positions =5509 #We know it from the matlab code\n",
    "times = Ux.shape[1]\n",
    "simulations = int(Ux.shape[0]/positions)\n",
    "print(\"We ran \", simulations, \"simulations with different parameters for each simulation (parameters of the stenosis and resistance of the blood flow in the bifurcations)\")\n",
    "print(\"1 simulation calculate the velocities of the blood flow at\", positions, \"different positions and at\", times, \"different times\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data preprocessing  <a name=\"preprocessing\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check if we have any NaN or None values in our dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(np.count_nonzero(np.isnan(Ux)))\n",
    "print(np.count_nonzero(np.isnan(Uy)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems there are __no None or NaN values__ so we can start direclty preprocess our datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's sample our data points into the following ratios. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1375, 110) (1375, 110)\n"
     ]
    }
   ],
   "source": [
    "ratio_pts = 0.01\n",
    "ratio_time = 1\n",
    "\n",
    "new_Ux, new_Uy, new_inds = sample(Ux, Uy, ratio_pts, ratio_time)\n",
    "print(new_Ux.shape, new_Uy.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With the sampling we got from 5509 positions to 55 positions\n",
      "With the sampling we got from 110 time steps to 110 time steps\n"
     ]
    }
   ],
   "source": [
    "new_Nu, new_Nt = get_Nu_Nt_sampled(Ux, new_Ux)\n",
    "\n",
    "print('With the sampling we got from', 5509, 'positions to', new_Nu, 'positions')\n",
    "print('With the sampling we got from', 110, 'time steps to', new_Nt, 'time steps')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can look at the positions of the sampled positions to make sure that we cover mostly all the important parts of the geometry of the artery."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_sampled_coord(new_inds) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's flatten our matrices into a 2D matrices with dimensions $(N_s, (2 N_u),  N_t)$. For each simulation, the x and y speed coordinates are compressed to the following 2D matrix:\n",
    "\n",
    "\n",
    "\n",
    "$$\n",
    "\\mathbf{M_{2D}}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "\\vdots & \\vdots & \\vdots & \\vdots \\\\\n",
    "u_{x}^{(0)} & u_{x}^{(1)} & \\cdots &\n",
    "u_{x}^{(N_t - 1)} \\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "u_{y}^{(0)} & u_{y}^{(1)} & \\cdots &\n",
    "u_{y}^{(N_t - 1)} \\\\\n",
    "\\vdots & \\vdots & \\vdots & \\vdots\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 110, 110)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flattened_array = flatten_2d(new_Ux, new_Uy, ratio_pts)\n",
    "flattened_array.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make a sanity check that the dimension of 1 datapoint is indeed $({2 * new_{N_t}, new_{N_u})}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert flattened_array.shape[1] == 2*new_Nu\n",
    "assert flattened_array.shape[2] == new_Nt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Pickle  <a name=\"pickle\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To avoid the loading and processing steps each time we open the notebook, we will save the processed matrix \"flattened_array\" using pickle. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following cell, we will create pickles for every subsampled data according to the ratios_pts and the ratios_t."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratios_pts = [0.1, 0.05, 0.02]\n",
    "ratios_t = [0.5, 0.25, 0.1]\n",
    "\n",
    "create_subsamples(Ux, Uy, ratios_pts, ratios_t, name_file='lstm_middle_small')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell above is only intented to be run __once__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Start from here if you the pickle file already exist in your data folder <a name=\"start_pickle\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change only the following cell to change the name of the file you want to open."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name of the file you want to read :  processed_lstm_middle_small_0.1_0.5\n"
     ]
    }
   ],
   "source": [
    "ratios = [0.1, 0.5]\n",
    "size = ['lstm_very_small', 'lstm_middle_small', 'lstm_small']\n",
    "\n",
    "name = 'processed_'+str(size[1])+'_'+str(ratios[0])+'_'+str(ratios[1])\n",
    "\n",
    "print('name of the file you want to read : ', name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "flattened_array = cPickle.load(open(\"data/pickle/\"+str(size[1])+\"/\"+name, \"rb\"))\n",
    "#flattened_array = flattened_array.reshape(flattened_array.shape[0], flattened_array.shape[2], flattened_array.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(175, 1100, 55)\n"
     ]
    }
   ],
   "source": [
    "print(flattened_array.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Final step : split train/test\n",
    "\n",
    "We split the data set into a training a testing set to be able to evaluate our autoencoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(157, 1100, 55)\n",
      "(18, 1100, 55)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test = train_test_split(flattened_array, test_size=0.1, random_state=seed)\n",
    "y_train, y_test = x_train, x_test\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. LSTM Auto-encoder  <a name=\"autoencoder\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 55\n",
    "seq_len = 1100\n",
    "hidden_size = 5\n",
    "model = LSTMAE(input_dim, hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMAE(\n",
       "  (encoder): Encoder(\n",
       "    (lstm_encoder): LSTM(55, 5, batch_first=True)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (lstm_decoder): LSTM(5, 5, batch_first=True)\n",
       "    (fc): Linear(in_features=5, out_features=55, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define network parameters\n",
    "learningRate=1e-3\n",
    "epochs=50\n",
    "input_size=x_train.shape[2]\n",
    "k_folds = 5\n",
    "\n",
    "# creates a criterion that measures the mean squared error (squared L2 norm) \n",
    "criterion = nn.MSELoss() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "FOLD 0\n",
      "--------------------------------\n",
      "Epoch:1/50 Training Error:0.995 Test Error:0.995\n",
      "Epoch:2/50 Training Error:0.992 Test Error:0.991\n",
      "Epoch:3/50 Training Error:0.988 Test Error:0.986\n",
      "Epoch:4/50 Training Error:0.984 Test Error:0.981\n",
      "Epoch:5/50 Training Error:0.980 Test Error:0.977\n",
      "Epoch:6/50 Training Error:0.975 Test Error:0.972\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-108-b49037d46076>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mKfold_lstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk_folds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearningRate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/ml-project-2-thevipers2/crossvalidation_lstm.py\u001b[0m in \u001b[0;36mKfold_lstm\u001b[0;34m(dataset, k_folds, input_size, epochs, criterion, learningRate, hidden_size, momentum, comment)\u001b[0m\n\u001b[1;32m     66\u001b[0m             \u001b[0mtrain_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_epoch_lstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0;31m# compute the relative training error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m             \u001b[0mtrain_error\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalid_epoch_lstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m             \u001b[0;31m# compute the relative test error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0mtest_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_epoch_lstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ml-project-2-thevipers2/LSTM.py\u001b[0m in \u001b[0;36mvalid_epoch_lstm\u001b[0;34m(test_data, net)\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m             \u001b[0;31m# predict the output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m             \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m             \u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0;31m# compute the relative error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ml-project-2-thevipers2/LSTM.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, return_last_h, return_enc_out)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_last_h\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_enc_out\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0mx_enc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m         \u001b[0mx_dec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_h\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_enc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ml-project-2-thevipers2/LSTM.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m         \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlast_h_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_c_state\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm_encoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m         \u001b[0mx_enc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlast_h_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0mx_enc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_enc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    689\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 691\u001b[0;31m             result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[0m\u001b[1;32m    692\u001b[0m                               self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[1;32m    693\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "Kfold_lstm(x_train, k_folds, input_dim, epochs, criterion, learningRate, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameters tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the best learning rate and momentums of our model using cross-validation :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define network parameters\n",
    "learning_rates = [1e-1, 1e-2, 1e-3, 1e-4, 1e-5] \n",
    "momentums = [0.1, 0.5, 0.7, 0.9, 0.99]\n",
    "epochs= 1\n",
    "input_size=x_train.shape[2]\n",
    "k_folds = 5\n",
    "dataset_name = \"middle_small\" #Only used to save the plot with the good name\n",
    "hidden_size = 5\n",
    "\n",
    "# creates a criterion that measures the mean squared error (squared L2 norm) \n",
    "criterion = nn.MSELoss()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mMomentum =  0.1\n",
      "\u001b[0m\n",
      "\u001b[1mLearning rate =  \u001b[1m0.1\n",
      "\u001b[0m\n",
      "Performance of 5 fold cross validation: \n",
      "Average Training Error: 0.969 \t Average Test Error: 0.970\n",
      " \n",
      "\u001b[1mLearning rate =  \u001b[1m0.01\n",
      "\u001b[0m\n",
      "Performance of 5 fold cross validation: \n",
      "Average Training Error: 0.997 \t Average Test Error: 0.998\n",
      " \n",
      "\u001b[1mLearning rate =  \u001b[1m0.001\n",
      "\u001b[0m\n",
      "Performance of 5 fold cross validation: \n",
      "Average Training Error: 1.000 \t Average Test Error: 1.000\n",
      " \n",
      "\u001b[1mLearning rate =  \u001b[1m0.0001\n",
      "\u001b[0m\n",
      "Performance of 5 fold cross validation: \n",
      "Average Training Error: 1.000 \t Average Test Error: 1.000\n",
      " \n",
      "\u001b[1mLearning rate =  \u001b[1m1e-05\n",
      "\u001b[0m\n",
      "Performance of 5 fold cross validation: \n",
      "Average Training Error: 1.000 \t Average Test Error: 1.001\n",
      " \n",
      "\u001b[1mMomentum =  0.5\n",
      "\u001b[0m\n",
      "\u001b[1mLearning rate =  \u001b[1m0.1\n",
      "\u001b[0m\n",
      "Performance of 5 fold cross validation: \n",
      "Average Training Error: 0.946 \t Average Test Error: 0.946\n",
      " \n",
      "\u001b[1mLearning rate =  \u001b[1m0.01\n",
      "\u001b[0m\n",
      "Performance of 5 fold cross validation: \n",
      "Average Training Error: 0.996 \t Average Test Error: 0.996\n",
      " \n",
      "\u001b[1mLearning rate =  \u001b[1m0.001\n",
      "\u001b[0m\n",
      "Performance of 5 fold cross validation: \n",
      "Average Training Error: 1.000 \t Average Test Error: 1.000\n",
      " \n",
      "\u001b[1mLearning rate =  \u001b[1m0.0001\n",
      "\u001b[0m\n",
      "Performance of 5 fold cross validation: \n",
      "Average Training Error: 1.000 \t Average Test Error: 1.000\n",
      " \n",
      "\u001b[1mLearning rate =  \u001b[1m1e-05\n",
      "\u001b[0m\n",
      "Performance of 5 fold cross validation: \n",
      "Average Training Error: 1.000 \t Average Test Error: 1.001\n",
      " \n",
      "\u001b[1mMomentum =  0.7\n",
      "\u001b[0m\n",
      "\u001b[1mLearning rate =  \u001b[1m0.1\n",
      "\u001b[0m\n",
      "Performance of 5 fold cross validation: \n",
      "Average Training Error: 0.921 \t Average Test Error: 0.922\n",
      " \n",
      "\u001b[1mLearning rate =  \u001b[1m0.01\n",
      "\u001b[0m\n",
      "Performance of 5 fold cross validation: \n",
      "Average Training Error: 0.993 \t Average Test Error: 0.993\n",
      " \n",
      "\u001b[1mLearning rate =  \u001b[1m0.001\n",
      "\u001b[0m\n",
      "Performance of 5 fold cross validation: \n",
      "Average Training Error: 1.000 \t Average Test Error: 1.000\n",
      " \n",
      "\u001b[1mLearning rate =  \u001b[1m0.0001\n",
      "\u001b[0m\n",
      "Performance of 5 fold cross validation: \n",
      "Average Training Error: 1.000 \t Average Test Error: 1.000\n",
      " \n",
      "\u001b[1mLearning rate =  \u001b[1m1e-05\n",
      "\u001b[0m\n",
      "Performance of 5 fold cross validation: \n",
      "Average Training Error: 1.000 \t Average Test Error: 1.001\n",
      " \n",
      "\u001b[1mMomentum =  0.9\n",
      "\u001b[0m\n",
      "\u001b[1mLearning rate =  \u001b[1m0.1\n",
      "\u001b[0m\n",
      "Performance of 5 fold cross validation: \n",
      "Average Training Error: 0.888 \t Average Test Error: 0.888\n",
      " \n",
      "\u001b[1mLearning rate =  \u001b[1m0.01\n",
      "\u001b[0m\n",
      "Performance of 5 fold cross validation: \n",
      "Average Training Error: 0.988 \t Average Test Error: 0.988\n",
      " \n",
      "\u001b[1mLearning rate =  \u001b[1m0.001\n",
      "\u001b[0m\n",
      "Performance of 5 fold cross validation: \n",
      "Average Training Error: 0.999 \t Average Test Error: 0.999\n",
      " \n",
      "\u001b[1mLearning rate =  \u001b[1m0.0001\n",
      "\u001b[0m\n",
      "Performance of 5 fold cross validation: \n",
      "Average Training Error: 1.000 \t Average Test Error: 1.000\n",
      " \n",
      "\u001b[1mLearning rate =  \u001b[1m1e-05\n",
      "\u001b[0m\n",
      "Performance of 5 fold cross validation: \n",
      "Average Training Error: 1.000 \t Average Test Error: 1.000\n",
      " \n",
      "\u001b[1mMomentum =  0.99\n",
      "\u001b[0m\n",
      "\u001b[1mLearning rate =  \u001b[1m0.1\n",
      "\u001b[0m\n",
      "Performance of 5 fold cross validation: \n",
      "Average Training Error: 0.871 \t Average Test Error: 0.871\n",
      " \n",
      "\u001b[1mLearning rate =  \u001b[1m0.01\n",
      "\u001b[0m\n",
      "Performance of 5 fold cross validation: \n",
      "Average Training Error: 0.983 \t Average Test Error: 0.983\n",
      " \n",
      "\u001b[1mLearning rate =  \u001b[1m0.001\n",
      "\u001b[0m\n",
      "Performance of 5 fold cross validation: \n",
      "Average Training Error: 0.999 \t Average Test Error: 0.999\n",
      " \n",
      "\u001b[1mLearning rate =  \u001b[1m0.0001\n",
      "\u001b[0m\n",
      "Performance of 5 fold cross validation: \n",
      "Average Training Error: 1.000 \t Average Test Error: 1.000\n",
      " \n",
      "\u001b[1mLearning rate =  \u001b[1m1e-05\n",
      "\u001b[0m\n",
      "Performance of 5 fold cross validation: \n",
      "Average Training Error: 1.000 \t Average Test Error: 1.000\n",
      " \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>m=0.1</th>\n",
       "      <th>m=0.5</th>\n",
       "      <th>m=0.7</th>\n",
       "      <th>m=0.9</th>\n",
       "      <th>m=0.99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lr=0.1</th>\n",
       "      <td>0.969823</td>\n",
       "      <td>0.997643</td>\n",
       "      <td>1.000225</td>\n",
       "      <td>1.000484</td>\n",
       "      <td>1.000510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lr=0.01</th>\n",
       "      <td>0.946148</td>\n",
       "      <td>0.995683</td>\n",
       "      <td>1.000028</td>\n",
       "      <td>1.000464</td>\n",
       "      <td>1.000508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lr=0.001</th>\n",
       "      <td>0.921942</td>\n",
       "      <td>0.993332</td>\n",
       "      <td>0.999791</td>\n",
       "      <td>1.000441</td>\n",
       "      <td>1.000506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lr=0.0001</th>\n",
       "      <td>0.888221</td>\n",
       "      <td>0.987865</td>\n",
       "      <td>0.999235</td>\n",
       "      <td>1.000385</td>\n",
       "      <td>1.000500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lr=1e-05</th>\n",
       "      <td>0.871482</td>\n",
       "      <td>0.983037</td>\n",
       "      <td>0.998731</td>\n",
       "      <td>1.000334</td>\n",
       "      <td>1.000495</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              m=0.1     m=0.5     m=0.7     m=0.9    m=0.99\n",
       "lr=0.1     0.969823  0.997643  1.000225  1.000484  1.000510\n",
       "lr=0.01    0.946148  0.995683  1.000028  1.000464  1.000508\n",
       "lr=0.001   0.921942  0.993332  0.999791  1.000441  1.000506\n",
       "lr=0.0001  0.888221  0.987865  0.999235  1.000385  1.000500\n",
       "lr=1e-05   0.871482  0.983037  0.998731  1.000334  1.000495"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\n",
      "Best learning rate is 0.1  with a best momentum of 0.99 with a best error of:  0.8714821026422757\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "results, best_result, best_lr, best_mom = tuning_lr_momentum_lstm(x_train, k_folds, input_size, epochs, criterion, learning_rates, hidden_size, momentums, dataset_name_=dataset_name, plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the best number of neurons in the latent space (neurons in the \"middle layer of the auto-encoder\") in the auto-encoder (which is actually the dimension of the compressed data) : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define network parameters\n",
    "lr = best_lr # from above\n",
    "epochs= 50\n",
    "input_size=x_train.shape[2]\n",
    "k_folds = 5\n",
    "hidden_sizes = [3, 5, 6, 8, 10]\n",
    "dataset_name = \"middle_small\" #Only used to save the plot with the good name\n",
    "\n",
    "# creates a criterion that measures the mean squared error (squared L2 norm) \n",
    "criterion = nn.MSELoss()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mNumber of neurons =  3\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "best_result, best_neurons_nb = tuning_latent_layer_lstm(x_train, k_folds, input_size, epochs, criterion, lr, hidden_sizes, dataset_name_=dataset_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's try with the tuned parameters and see how it goes along the epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define network parameters\n",
    "learningRate= best_lr\n",
    "epochs=50\n",
    "input_size=x_train.shape[1]\n",
    "k_folds = 3\n",
    "hidden_size_ = best_neurons_nb\n",
    "\n",
    "# creates a criterion that measures the mean squared error (squared L2 norm) \n",
    "criterion = nn.MSELoss() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "FOLD 0\n",
      "--------------------------------\n",
      "Epoch:1/50 Training Error:0.916 Test Error:0.911\n",
      "Epoch:2/50 Training Error:0.839 Test Error:0.828\n",
      "Epoch:3/50 Training Error:0.806 Test Error:0.792\n",
      "Epoch:4/50 Training Error:0.795 Test Error:0.780\n",
      "Epoch:5/50 Training Error:0.792 Test Error:0.777\n",
      "Epoch:6/50 Training Error:0.791 Test Error:0.776\n",
      "Epoch:7/50 Training Error:0.790 Test Error:0.775\n",
      "Epoch:8/50 Training Error:0.790 Test Error:0.774\n",
      "Epoch:9/50 Training Error:0.789 Test Error:0.774\n",
      "Epoch:10/50 Training Error:0.789 Test Error:0.773\n",
      "Epoch:11/50 Training Error:0.788 Test Error:0.773\n",
      "Epoch:12/50 Training Error:0.788 Test Error:0.772\n",
      "Epoch:13/50 Training Error:0.788 Test Error:0.772\n",
      "Epoch:14/50 Training Error:0.787 Test Error:0.772\n",
      "Epoch:15/50 Training Error:0.787 Test Error:0.772\n",
      "Epoch:16/50 Training Error:0.787 Test Error:0.772\n",
      "Epoch:17/50 Training Error:0.787 Test Error:0.772\n",
      "Epoch:18/50 Training Error:0.787 Test Error:0.772\n",
      "Epoch:19/50 Training Error:0.787 Test Error:0.772\n",
      "Epoch:20/50 Training Error:0.787 Test Error:0.772\n",
      "Epoch:21/50 Training Error:0.787 Test Error:0.772\n",
      "Epoch:22/50 Training Error:0.787 Test Error:0.772\n",
      "Epoch:23/50 Training Error:0.787 Test Error:0.772\n",
      "Epoch:24/50 Training Error:0.787 Test Error:0.772\n",
      "Epoch:25/50 Training Error:0.787 Test Error:0.772\n",
      "Epoch:26/50 Training Error:0.787 Test Error:0.772\n",
      "Epoch:27/50 Training Error:0.787 Test Error:0.772\n",
      "Epoch:28/50 Training Error:0.787 Test Error:0.772\n",
      "Epoch:29/50 Training Error:0.787 Test Error:0.772\n",
      "Epoch:30/50 Training Error:0.787 Test Error:0.772\n",
      "Epoch:31/50 Training Error:0.787 Test Error:0.772\n",
      "Epoch:32/50 Training Error:0.787 Test Error:0.772\n",
      "Epoch:33/50 Training Error:0.787 Test Error:0.772\n",
      "Epoch:34/50 Training Error:0.787 Test Error:0.772\n",
      "Epoch:35/50 Training Error:0.787 Test Error:0.772\n",
      "Epoch:36/50 Training Error:0.787 Test Error:0.772\n",
      "Epoch:37/50 Training Error:0.787 Test Error:0.772\n",
      "Epoch:38/50 Training Error:0.787 Test Error:0.772\n",
      "Epoch:39/50 Training Error:0.787 Test Error:0.772\n",
      "Epoch:40/50 Training Error:0.787 Test Error:0.771\n",
      "Epoch:41/50 Training Error:0.787 Test Error:0.771\n",
      "Epoch:42/50 Training Error:0.787 Test Error:0.771\n",
      "Epoch:43/50 Training Error:0.787 Test Error:0.771\n",
      "Epoch:44/50 Training Error:0.786 Test Error:0.771\n",
      "Epoch:45/50 Training Error:0.786 Test Error:0.770\n",
      "Epoch:46/50 Training Error:0.785 Test Error:0.770\n",
      "Epoch:47/50 Training Error:0.785 Test Error:0.770\n",
      "Epoch:48/50 Training Error:0.785 Test Error:0.770\n",
      "Epoch:49/50 Training Error:0.785 Test Error:0.770\n",
      "Epoch:50/50 Training Error:0.785 Test Error:0.770\n",
      "--------------------------------\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "Epoch:1/50 Training Error:0.932 Test Error:0.923\n",
      "Epoch:2/50 Training Error:0.849 Test Error:0.832\n",
      "Epoch:3/50 Training Error:0.820 Test Error:0.802\n",
      "Epoch:4/50 Training Error:0.808 Test Error:0.788\n",
      "Epoch:5/50 Training Error:0.804 Test Error:0.785\n",
      "Epoch:6/50 Training Error:0.802 Test Error:0.783\n",
      "Epoch:7/50 Training Error:0.802 Test Error:0.782\n",
      "Epoch:8/50 Training Error:0.801 Test Error:0.782\n",
      "Epoch:9/50 Training Error:0.801 Test Error:0.781\n",
      "Epoch:10/50 Training Error:0.801 Test Error:0.781\n",
      "Epoch:11/50 Training Error:0.801 Test Error:0.781\n",
      "Epoch:12/50 Training Error:0.800 Test Error:0.781\n",
      "Epoch:13/50 Training Error:0.800 Test Error:0.781\n",
      "Epoch:14/50 Training Error:0.800 Test Error:0.781\n",
      "Epoch:15/50 Training Error:0.800 Test Error:0.781\n",
      "Epoch:16/50 Training Error:0.800 Test Error:0.780\n",
      "Epoch:17/50 Training Error:0.799 Test Error:0.780\n",
      "Epoch:18/50 Training Error:0.799 Test Error:0.780\n",
      "Epoch:19/50 Training Error:0.799 Test Error:0.779\n",
      "Epoch:20/50 Training Error:0.798 Test Error:0.779\n",
      "Epoch:21/50 Training Error:0.798 Test Error:0.778\n",
      "Epoch:22/50 Training Error:0.798 Test Error:0.778\n",
      "Epoch:23/50 Training Error:0.798 Test Error:0.778\n",
      "Epoch:24/50 Training Error:0.798 Test Error:0.778\n",
      "Epoch:25/50 Training Error:0.798 Test Error:0.778\n",
      "Epoch:26/50 Training Error:0.797 Test Error:0.777\n",
      "Epoch:27/50 Training Error:0.795 Test Error:0.776\n",
      "Epoch:28/50 Training Error:0.795 Test Error:0.775\n",
      "Epoch:29/50 Training Error:0.795 Test Error:0.775\n",
      "Epoch:30/50 Training Error:0.795 Test Error:0.775\n",
      "Epoch:31/50 Training Error:0.795 Test Error:0.775\n",
      "Epoch:32/50 Training Error:0.794 Test Error:0.774\n",
      "Epoch:33/50 Training Error:0.794 Test Error:0.774\n",
      "Epoch:34/50 Training Error:0.794 Test Error:0.774\n",
      "Epoch:35/50 Training Error:0.794 Test Error:0.774\n",
      "Epoch:36/50 Training Error:0.794 Test Error:0.774\n",
      "Epoch:37/50 Training Error:0.794 Test Error:0.774\n",
      "Epoch:38/50 Training Error:0.794 Test Error:0.774\n",
      "Epoch:39/50 Training Error:0.794 Test Error:0.774\n",
      "Epoch:40/50 Training Error:0.794 Test Error:0.774\n",
      "Epoch:41/50 Training Error:0.794 Test Error:0.774\n",
      "Epoch:42/50 Training Error:0.794 Test Error:0.774\n",
      "Epoch:43/50 Training Error:0.794 Test Error:0.774\n",
      "Epoch:44/50 Training Error:0.794 Test Error:0.774\n",
      "Epoch:45/50 Training Error:0.794 Test Error:0.774\n",
      "Epoch:46/50 Training Error:0.794 Test Error:0.774\n",
      "Epoch:47/50 Training Error:0.794 Test Error:0.774\n",
      "Epoch:48/50 Training Error:0.794 Test Error:0.774\n",
      "Epoch:49/50 Training Error:0.794 Test Error:0.774\n",
      "Epoch:50/50 Training Error:0.794 Test Error:0.774\n",
      "--------------------------------\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "Epoch:1/50 Training Error:0.893 Test Error:0.911\n",
      "Epoch:2/50 Training Error:0.807 Test Error:0.839\n",
      "Epoch:3/50 Training Error:0.778 Test Error:0.813\n",
      "Epoch:4/50 Training Error:0.773 Test Error:0.809\n",
      "Epoch:5/50 Training Error:0.772 Test Error:0.808\n",
      "Epoch:6/50 Training Error:0.771 Test Error:0.808\n",
      "Epoch:7/50 Training Error:0.771 Test Error:0.807\n",
      "Epoch:8/50 Training Error:0.770 Test Error:0.807\n",
      "Epoch:9/50 Training Error:0.770 Test Error:0.806\n",
      "Epoch:10/50 Training Error:0.769 Test Error:0.806\n",
      "Epoch:11/50 Training Error:0.769 Test Error:0.806\n",
      "Epoch:12/50 Training Error:0.769 Test Error:0.806\n",
      "Epoch:13/50 Training Error:0.769 Test Error:0.806\n",
      "Epoch:14/50 Training Error:0.769 Test Error:0.805\n",
      "Epoch:15/50 Training Error:0.768 Test Error:0.805\n",
      "Epoch:16/50 Training Error:0.768 Test Error:0.805\n",
      "Epoch:17/50 Training Error:0.768 Test Error:0.805\n",
      "Epoch:18/50 Training Error:0.768 Test Error:0.805\n",
      "Epoch:19/50 Training Error:0.768 Test Error:0.805\n",
      "Epoch:20/50 Training Error:0.768 Test Error:0.805\n",
      "Epoch:21/50 Training Error:0.768 Test Error:0.805\n",
      "Epoch:22/50 Training Error:0.768 Test Error:0.805\n",
      "Epoch:23/50 Training Error:0.768 Test Error:0.805\n",
      "Epoch:24/50 Training Error:0.768 Test Error:0.805\n",
      "Epoch:25/50 Training Error:0.768 Test Error:0.805\n",
      "Epoch:26/50 Training Error:0.768 Test Error:0.805\n",
      "Epoch:27/50 Training Error:0.768 Test Error:0.805\n",
      "Epoch:28/50 Training Error:0.768 Test Error:0.805\n",
      "Epoch:29/50 Training Error:0.768 Test Error:0.805\n",
      "Epoch:30/50 Training Error:0.768 Test Error:0.805\n",
      "Epoch:31/50 Training Error:0.768 Test Error:0.805\n",
      "Epoch:32/50 Training Error:0.768 Test Error:0.805\n",
      "Epoch:33/50 Training Error:0.768 Test Error:0.805\n",
      "Epoch:34/50 Training Error:0.768 Test Error:0.805\n",
      "Epoch:35/50 Training Error:0.768 Test Error:0.805\n",
      "Epoch:36/50 Training Error:0.767 Test Error:0.804\n",
      "Epoch:37/50 Training Error:0.767 Test Error:0.804\n",
      "Epoch:38/50 Training Error:0.767 Test Error:0.804\n",
      "Epoch:39/50 Training Error:0.767 Test Error:0.804\n",
      "Epoch:40/50 Training Error:0.767 Test Error:0.804\n",
      "Epoch:41/50 Training Error:0.767 Test Error:0.804\n",
      "Epoch:42/50 Training Error:0.767 Test Error:0.804\n",
      "Epoch:43/50 Training Error:0.767 Test Error:0.804\n",
      "Epoch:44/50 Training Error:0.767 Test Error:0.804\n",
      "Epoch:45/50 Training Error:0.767 Test Error:0.804\n",
      "Epoch:46/50 Training Error:0.767 Test Error:0.804\n",
      "Epoch:47/50 Training Error:0.767 Test Error:0.804\n",
      "Epoch:48/50 Training Error:0.767 Test Error:0.804\n",
      "Epoch:49/50 Training Error:0.767 Test Error:0.804\n",
      "Epoch:50/50 Training Error:0.767 Test Error:0.804\n",
      "Performance of 3 fold cross validation: \n",
      "Average Training Error: 0.782 \t Average Test Error: 0.783\n",
      " \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.7827695575698174"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Kfold_lstm(x_train, k_folds, input_size, epochs, criterion, learningRate, hidden_size_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quality of the compression on the test set using the tuned parameters :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now train and test our auto-encoder for different sample size of our initial dataset. To do so we will do a batch processing and store the final train and test errors. See the report to see the nice comparison table :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os \n",
    "import _pickle as cPickle\n",
    "\n",
    "dataset = 'middle_small'\n",
    "file_location = os.path.join('data', 'pickle', dataset, '*')\n",
    "filenames = glob.glob(file_location)\n",
    "i=0 \n",
    "\n",
    "\n",
    "# define the parameters of the model\n",
    "learningRate= best_lr\n",
    "hidden_size_ = best_neurons_nb\n",
    "\n",
    "epochs=50\n",
    "criterion = nn.MSELoss() \n",
    "\n",
    "test_errors = []\n",
    "train_errors = []\n",
    "\n",
    "for f in filenames:\n",
    "    #Load the data\n",
    "    x  = cPickle.load(open(f, \"rb\"))\n",
    "    \n",
    "    #Split\n",
    "    x_train, x_test = train_test_split(x, test_size=0.1, random_state=seed)\n",
    "    y_train, y_test = x_train, x_test\n",
    "    \n",
    "    #Declare the model\n",
    "    input_size=x_train.shape[1]\n",
    "    model = LSTMAE(input_size, hidden_size_)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learningRate, weight_decay=1e-5)\n",
    "    \n",
    "    #Dataloader\n",
    "    train_loader = DataLoader(x_train)\n",
    "    test_loader = DataLoader(x_test)\n",
    "    \n",
    "    #Training and testing over the epochs\n",
    "    for epoch in range(epochs):\n",
    "        # train the model \n",
    "        train_loss=train_epoch_lstm(train_loader, model, criterion, optimizer)\n",
    "        # compute the relative training error\n",
    "        train_error = valid_epoch_lstm(train_loader, model)\n",
    "        # compute the relative test error\n",
    "        test_error=valid_epoch_lstm(test_loader, model)\n",
    "    \n",
    "    #Save the last epoch train and test errors\n",
    "    test_errors.append(test_error)\n",
    "    train_errors.append(train_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "All arrays must be of the same length",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-130-693f54639d4d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m results = DataFrame({'' : ['50%', '25%', '10%'],\n\u001b[0m\u001b[1;32m      4\u001b[0m                    \u001b[0;34m'10%'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mtest_errors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                    \u001b[0;34m'5%'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mtest_errors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    612\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m             \u001b[0;31m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 614\u001b[0;31m             \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict_to_mgr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtyp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmanager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    615\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m             \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmrecords\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36mdict_to_mgr\u001b[0;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[1;32m    462\u001b[0m         \u001b[0;31m# TODO: can we get rid of the dt64tz special case above?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 464\u001b[0;31m     return arrays_to_mgr(\n\u001b[0m\u001b[1;32m    465\u001b[0m         \u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtyp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtyp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconsolidate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m     )\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, arr_names, index, columns, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;31m# figure out the index, if necessary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_extract_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36m_extract_index\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    633\u001b[0m             \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_lengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"All arrays must be of the same length\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhave_dicts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: All arrays must be of the same length"
     ]
    }
   ],
   "source": [
    "from pandas import *\n",
    "\n",
    "results = DataFrame({'' : ['50%', '25%', '10%'],\n",
    "                   '10%' : test_errors[:3],\n",
    "                   '5%' : test_errors[3:6],\n",
    "                   '2%' : test_errors[6:9]})\n",
    "\n",
    "results = results.set_index('')\n",
    "\n",
    "display(results)\n",
    "print(\"\\033[1m\" + 'Table of relative error depending on the sampling of the dataset' + \"\\033[0m\")\n",
    "print('x : sampling of times')\n",
    "print('y : sampling of positions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save in pickles\n",
    "\n",
    "name = \"lstm_train_errors_\" + dataset\n",
    "cPickle.dump( train_errors , open( name, \"wb\" ) )\n",
    "name = \"lstm_test_errors_\" + dataset\n",
    "cPickle.dump( test_errors , open( name, \"wb\" ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Discussion & conclusion <a name=\"ccl\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
