# Machine Learning - Project 2 

## *Unsteady parametrized Stokes equations in a 2D arterial bifurcation with stenosis: design of an Autoencoder for data compression*

## General information 

The repository contains the code for Machine Learning course (CS-433) 2021 for the __ML4Science__ project 2 at EPFL. Our project aims at investigating the relationship between classical numerical methods and deep-learning techniques, with the final purpose of efficiently providing accurate solutions to parametrized PDE problems, being fully unaware of the values of the characteristic parameters. The professor's Deparis lab has developed efficient numerical methods for the resolution of parametrized time-dependent PDEs. In the following, we develop deep-learning models that take advantage of these numerical methods to solve parametrized unsteady PDEs without any knowledge of the characteristic parameters. 

In this work we make progress to this end by proposing deep-learning approaches to identify and evolve a __low-dimensional__ representation of a spatiotemporal system. In particular, we employ _Feed-Forward AEs_ and _Long short-term memory AEs_, or LSTM AEs, to learn an optimal low-dimensional representation of the full state of the system. We use _Pytorch_ for their implementation.

### Team members
The project is accomplished by the team `TheVipers` with members:

- Camille Frayssinhes: [@camillefrayssinhes](https://github.com/camillefrayssinhes)
- Assia Ouanaya: [@assiaoua](https://github.com/assiaoua)
- Theau Vannier: [@theauv](https://github.com/theauv)

### Data
The data used in our work describes the __blood flow__ in an artery with a bifurcation and a stenosis. This data set was obtained by running multiple simulations which solve unsteady Navier-Stokes equations with random generated stenosis parameters on MatLab. There are 5 stenosis parameters that can be set at the beginning of the experiment: µ<sub>1</sub> stenosis width, µ<sub>2</sub> stenosis height, µ<sub>3</sub> distance between the 2 stenosis plaque centers, R<sub>1</sub> resistive term of the first bifurcation and R<sub>2</sub> resistive term of the second bifurcation as well as the final number of simulations.  
<p align="center">
  <img src="/img/nice_illustration.png" alt="params" width="500"/>
</p> 

The data simulator generetes 4 files:  
- u1.csv: which represents the x coordinate of the blood speed in the artery
- u2.csv: which represents the y coordinate of the blood speed in the artery
- p.csv: which represents the blood pressure in the artery
- params.csv: which represents the stenosis parameters


### How to run the code
The project has been developed and tested with `python3.8`.
The required library for running the models and training is `numpy1.20.1`.
The library for visualization is `matplotlib3.3.4`.

### How to reproduce the obtained results

The final results used to predict the test datasets are generated by running the function implemented in ... by using the command ...
And the final results are saved in: ...

***
## Project architecture

### Helper functions

`helpers.py`: loading CSV training and testing data & spatial visualization of the arterial bifurcation data points.

### Processing data 

`preprocessing.py`: preprocessing training and test data for model prediction.

### AE models

`autoencoder.py`: feed-forward autoencoder implementation.

`LSTM.py`: LSTM autoencoder implementation.

### Selecting model

`crossvalidation.py`: using cross-validation to search for the best parameters(lambda & number latent neurons) to obtain the best test errors.

`crossvalidation_lstm.py`: using cross-validation to search for the best parameters(lambda, momentum & hidden size) to obtain the best test errors.


### Notebook

`main.ipynb`: data exploration and preprocessing. Deployment of Feed-Forward Autoencoder by tuning the best parameters through cross validation. Analysis and visualisation of the test and training errors with different choices of parameters.

`lstm_main.ipynb`: data exploration and preprocessing. Deployment of Recurrent LSTM Autoencoder by tuning the best parameters through cross validation. Analysis and visualisation of the test and training errors with different choices of parameters.


### Report

`documents/report.pdf`: a 4-pages report of the project.


***
## AE architecture

### Feed-forward AE

Consists of fully-connected layers stacked on top of each other. 

<p align="center">
  <img src="/img/Architecture.png" alt="Feed_Architecture" width="500"/>
</p>

### LSTM AE

Autoencoder for sequences of matrices which consists of stacked LSTMs.

<p align="center">
  <img src="/img/Architecture_lstm.png" alt="Architecture_lstm" width="500"/>
</p>

***
## References
[1]Dal Santo, N., Deparis, S., and Pegolotti, L., “Data driven approximation of parametrized PDEs by reduced basis and neural networks”, <i>Journal of Computational Physics</i>, vol. 416, 2020. doi:10.1016/j.jcp.2020.109550.

